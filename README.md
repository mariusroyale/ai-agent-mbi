# AI Agent MBI - Jira Ticket Classification System

An intelligent AI-powered agent designed to classify and process Jira tickets using advanced machine learning techniques. MBI (codename) leverages multiple LLM providers and vector search capabilities to provide accurate ticket classification and insights.

## ğŸš€ Features

- **Multi-LLM Support**: Integrates with OpenAI, GPT4All, and HuggingFace models
- **Vector Search**: Powered by FAISS for efficient similarity search
- **Jira Integration**: Direct integration with Jira API for ticket management
- **Flexible Configuration**: Environment-based configuration management
- **Extensible Architecture**: Modular design supporting multiple LLM clients
- **REST API**: Built-in API server for easy integration

## ğŸ› ï¸ Tech Stack

- **Python 3.9+**: Core programming language
- **OpenAI API**: Primary LLM provider
- **LlamaIndex**: Document indexing and retrieval
- **FAISS**: Vector similarity search
- **Jira API**: Ticket management integration
- **Pydantic**: Data validation and settings management
- **Uvicorn**: ASGI server for API endpoints
- **Sentence Transformers**: Text embeddings

## ğŸ“‹ Requirements

- Python 3.9 or higher
- Poetry (for dependency management)
- Active Jira instance with API access
- OpenAI API key (optional: HuggingFace API key)

## ğŸ”§ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/mariusroyale/ai-agent-mbi.git
cd ai-agent-mbi
```

### 2. Install Dependencies

Using Poetry (recommended):

```bash
poetry install
```

Or using pip:

```bash
pip install -r requirements.txt
```

### 3. Environment Configuration

Create a `.env` file in the project root with the following variables:

```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1

# Jira Configuration
JIRA_SERVER=https://your-company.atlassian.net
JIRA_EMAIL=your-email@company.com
JIRA_API_TOKEN=your_jira_api_token

# Optional: HuggingFace
HUGGINGFACE_API_KEY=your_huggingface_api_key

# Optional: LlamaIndex
LLAMA_INDEX_API_KEY=your_llama_index_api_key

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Application Settings
LOG_LEVEL=INFO
ENV=development
```

### 4. Set Up Jira API Token

1. Go to your Atlassian Account Settings
2. Navigate to Security â†’ API tokens
3. Create a new API token
4. Copy the token to your `.env` file

## ğŸš€ Usage

### Starting the Application

```bash
# Using Poetry
PYTHONPATH=src poetry run python -m uvicorn src.main:app --host 0.0.0.0 --port 8000

# Or directly with Python
PYTHONPATH=src python -m uvicorn src.main:app --host 0.0.0.0 --port 8000
```
ğŸ‘‰ http://0.0.0.0:8000/

### Basic Usage Example

```python
from src.config import config
from src.llm.client_factory import LLMClientFactory
from src.services.search_vector import VectorSearchService

# Initialize LLM client
llm_client = LLMClientFactory.create_client("openai")

# Classify a ticket
ticket_description = "User cannot login to the application"
classification = llm_client.chat([
    {"role": "user", "content": f"Classify this ticket: {ticket_description}"}
])

print(f"Classification: {classification}")
```

## ğŸ“ Project Structure

```
ai-agent-mbi/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â””â”€â”€ agent_007.py          # Main agent implementation
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ base_client.py        # Abstract base class for LLM clients
â”‚   â”‚   â”œâ”€â”€ client_factory.py     # Factory pattern for client creation
â”‚   â”‚   â”œâ”€â”€ openai_client.py      # OpenAI API client
â”‚   â”‚   â””â”€â”€ gpt4all_client.py     # GPT4All local client
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ search_vector.py      # Vector search service
â”‚   â”œâ”€â”€ tests/                    # Test files
â”‚   â””â”€â”€ config.py                 # Configuration management
â”œâ”€â”€ data_mock/                    # Mock data for testing
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ pyproject.toml               # Poetry configuration
â””â”€â”€ README.md                    # This file
```

## ğŸ”Œ API Endpoints

The application exposes REST API endpoints for ticket classification:

### POST `/classify`
Classify a Jira ticket based on its content.

**Request Body:**
```json
{
    "ticket_id": "PROJ-123",
    "summary": "User login issue",
    "description": "User cannot access the application after password reset"
}
```

**Response:**
```json
{
    "ticket_id": "PROJ-123",
    "classification": "Authentication Issue",
    "confidence": 0.95,
    "suggested_assignee": "security-team",
    "priority": "high"
}
```

## ğŸ§ª Testing

Run the test suite:

```bash
# Using Poetry
poetry run pytest src/tests/

# Or directly
python -m pytest src/tests/
```

## ğŸ“Š Configuration Options

The application supports various configuration options through environment variables:

| Variable         | Default       | Description             |
|------------------|---------------|-------------------------|
| `OPENAI_API_KEY` | Required      | OpenAI API key          |
| `JIRA_SERVER`    | Required      | Jira server URL         |
| `JIRA_EMAIL`     | Required      | Jira user email         |
| `JIRA_API_TOKEN` | Required      | Jira API token          |
| `API_HOST`       | `0.0.0.0`     | API server host         |
| `API_PORT`       | `8000`        | API server port         |
| `LOG_LEVEL`      | `INFO`        | Logging level           |
| `ENV`            | `development` | Environment mode        |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Marius Iordache**
- Email: marius.technical.leader@gmail.com
- GitHub: [@mariusroyale](https://github.com/mariusroyale)

## ğŸ™ Acknowledgments

- OpenAI for providing the GPT models
- Meta for LlamaIndex framework
- Facebook AI Research for FAISS
- The open-source community for the amazing tools and libraries

## ğŸ“ Support

If you have any questions or need help setting up the project, please:

1. Check the existing [Issues](https://github.com/mariusroyale/ai-agent-mbi/issues)
2. Create a new issue if your question isn't already addressed
3. Reach out via email for urgent matters

---

**Note**: This project is under active development. Features and API endpoints may change. Please check the latest documentation before deploying to production.
